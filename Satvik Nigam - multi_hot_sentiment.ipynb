{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir_eRnOIbTTz"
   },
   "source": [
    "# Text classification \n",
    "## Sentiment analysis\n",
    "It is a natural language processing problem where text is understood and the underlying intent is predicted. Here, you need to  predict the sentiment of movie reviews as either positive or negative in Python using the Keras deep learning library.\n",
    "\n",
    "## Data description\n",
    "The dataset is the Large Movie Review Dataset often referred to as the IMDB dataset.\n",
    "\n",
    "The [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) (often referred to as the IMDB dataset) contains 25,000 highly polar movie reviews (good or bad) for training and the same amount again for testing. The problem is to determine whether a given moving review has a positive or negative sentiment.  Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGs6auYKbvZ9"
   },
   "source": [
    "## Loading dataset\n",
    "First, we will load complete dataset and analyze some properties of it.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqXjhXycZqpP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import keras\n",
    "from keras import regularizers,layers\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lUt9_CxbwGH"
   },
   "outputs": [],
   "source": [
    "# np.load is used inside imdb.load_data. But imdb.load_data still assumes the default \n",
    "# values of an older version of numpy. So necessary changes to np.load are made\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load Numpy\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ln3lVLwypnp7",
    "outputId": "c8c3d974-5881-41c3-e465-23ab1401de4d"
   },
   "outputs": [],
   "source": [
    "# call load_data with allow_pickle implicitly set to true\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDAIVK_rcQCr"
   },
   "source": [
    "## **Let's see some of reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "QR3E0YIQcQtg",
    "outputId": "2f3e322c-a925-44df-f3b2-9621c3e6f58d"
   },
   "outputs": [],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "for i in range(15,20):\n",
    "  print(\"********************************************\")\n",
    "  print(' '.join(id_to_word.get(id - 3, '?')for id in X_train[i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJRXGZDgdUAL"
   },
   "source": [
    "## Summarize the data\n",
    "1) Find out the number of classes in label (*y* array)? <br>\n",
    "2) Find out number of unique words in dataset *X*?  <br>\n",
    "3) Calculate the list of review length , report mean and standard deviation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "_ArrM01ldvAL",
    "nbgrader": {
     "checksum": "8b319945d93218bc4097b381a4866fc1",
     "grade": false,
     "grade_id": "cell-41893f0c3efb31e1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize_data():\n",
    "  \"\"\"\n",
    "  Output:\n",
    "                    classes: list, list of unique classes in y  \n",
    "                no_of_words: int, number of unique words in dataset x \n",
    "     list_of_review_lengths: list,  list of lengths of each review \n",
    "         mean_review_length: float, mean(list_of_review_lengths), a single floating point value\n",
    "          std_review_length: float, standard_deviation(list_of_review_lengths), a single floating point value\n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return classes, no_of_words, list_of_review_lengths, mean_review_length, std_review_length\n",
    "\n",
    "\n",
    "classes, no_of_words, list_of_review_lengths, mean_review_length, std_review_length = summarize_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TFb9q7nOeKX1",
    "outputId": "75ad8976-eca6-4f76-d101-11a9c822fe33"
   },
   "outputs": [],
   "source": [
    "'''test for summarize_data'''\n",
    "def test_summarize_data():\n",
    "  assert classes.tolist() == [0,1]\n",
    "  assert no_of_words == 9998\n",
    "  assert np.isclose(mean_review_length, 234.75892, atol = 0.001)\n",
    "  assert np.isclose(std_review_length, 172.91149458735703, atol = 0.001)\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_summarize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wNyXu7gzgXVf",
    "outputId": "3c528145-aa89-44da-b787-d84ee818f7d0"
   },
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wT-EnTzt1ZZ1"
   },
   "source": [
    "## One hot encode the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ag1bLU021mwQ",
    "nbgrader": {
     "checksum": "387e9a11fdb2f5f630aa358e57c3e007",
     "grade": false,
     "grade_id": "cell-25ffdbcc436121e4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    y: numpy array with class labels\n",
    "  Outputs:\n",
    "    y_oh: numpy array with corresponding one-hot encodings\n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return y_oh\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjgVZKngfRLd"
   },
   "source": [
    "### Multi-hot encode the input data\n",
    "\n",
    "All sequences are of different length and our vocabulory size is 10K.  <br>\n",
    "**To Do**<br>\n",
    "1) Intialize vector of dimension 10,000 with value 0. <br>\n",
    "2) For those tokens in a sequence which are present in Vocabulary make that position as 1 and keep all other positions filled with 0. <br>\n",
    "For example, lets take Vocabulary = ['I': 0, ':1, 'eat: 2:' mango: 3, 'fruit':4, 'happy':5, 'you':6] <br>\n",
    "We have two sequnces and \n",
    "Multi-hot encoding of both sequences will be of dimension:  7 (vocab size).<br>\n",
    "1) *Mango is my favourite fruit* becomes *Mango ? ? ? fruit* after removing words which are not in my vocabulary. Hence multi hot encoding will have two 1's corresponding to mango and fruit i.e, [0, 0, 0, 1, 1, 0, 0] <br>\n",
    "Similarly, <br>\n",
    "  2) *I love to eat mango*  = *I ? ? eat mango*  =  [1, 1, 0, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "EGCeyTiUTn0F",
    "nbgrader": {
     "checksum": "6464e41d2c2e970a418b5c31dada227e",
     "grade": false,
     "grade_id": "cell-9621fa777a6091d7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def multi_hot_encode(sequences, dimension):\n",
    "  \"\"\"\n",
    "    Input:\n",
    "          sequences: list of sequences in X_train or X_test\n",
    "\n",
    "    Output:\n",
    "          results: mult numpy matrix of shape(len(sequences), dimension)\n",
    "                  \n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "38PMImZBTn94",
    "outputId": "ef9ef602-bd78-4a53-d50e-71958922ad07"
   },
   "outputs": [],
   "source": [
    "x_train = multi_hot_encode(X_train, 10000)\n",
    "x_test = multi_hot_encode(X_test, 10000)\n",
    "\n",
    "print(\"x_train \", x_train.shape)\n",
    "print(\"x_test \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ARBo_Ngptkd0",
    "outputId": "32005751-0aa8-4548-92f2-c8f33bb03e75"
   },
   "outputs": [],
   "source": [
    "'''test for pad_sequences'''\n",
    "def test_multi_hot_encode():\n",
    "  assert np.sum(x_train[1]) == 121.0\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_multi_hot_encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHMmE0Bcyyvr"
   },
   "source": [
    "## Split the data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bObjhuuUewPs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_strat, x_dev, y_strat, y_dev = train_test_split(x_train, y_train,test_size=0.40,random_state=0, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-oxp-ZchFin"
   },
   "source": [
    "## Build Model\n",
    "Build a multi layered feed forward network in keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyIsmvSejTK5"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "deletable": false,
    "id": "qVkxB48rijyA",
    "nbgrader": {
     "checksum": "896570e2d65bfdffc030e1b27e78c7e1",
     "grade": false,
     "grade_id": "cell-39c47f89f7634b15",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "e42a549b-40f9-4b95-c2b5-583aaa9ad58a"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        model: A compiled keras model\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return model\n",
    "  \n",
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afBSknLSjXRB"
   },
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "deletable": false,
    "id": "eJ8r5bfeiuON",
    "nbgrader": {
     "checksum": "e3871b03408d711869d928b6f49b774b",
     "grade": false,
     "grade_id": "cell-54b19898dc10302f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "2d6b3aa6-32aa-46ef-ffa8-a1257f688542"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def fit(model):\n",
    "    \"\"\"\n",
    "    Action:\n",
    "        Fit the model created above using training data as x_strat and y_strat\n",
    "        and validation_data as x_dev and y_dev, verbose=2 and store it in 'history' variable.\n",
    "        \n",
    "        evaluate the model using x_test, y_test, verbose=0 and store it in 'scores' list\n",
    "    Output:\n",
    "        scores: list of length 2\n",
    "        history_dict: output of history.history where history is output of model.fit()\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return scores,history_dict\n",
    "    \n",
    "scores,history_dict = fit(model)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pXsHW0SJsELv",
    "outputId": "6f83cfee-b38c-4856-b320-b1124264a097"
   },
   "outputs": [],
   "source": [
    "Accuracy=scores[1]*100\n",
    "print('Accuracy of your model is')\n",
    "print(scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "XFcUY3wOw_qQ",
    "outputId": "1165ab28-92bd-4218-d4bb-b694d86b760e"
   },
   "outputs": [],
   "source": [
    "history_dict['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJblDP18tWP_"
   },
   "source": [
    "### Verify whether training in converged or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "2KXUomrZbeH4",
    "outputId": "eb7fdb62-6d3b-40a2-922f-3a249b80f2b1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, (len(history_dict['loss']) + 1))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "dZOHI_xLbeN0",
    "outputId": "c7bab25e-e5b8-4c09-fe98-7cdc5167f450"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, (len(history_dict['acc']) + 1))\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOOt2bAUd4Is"
   },
   "source": [
    "### Advanced\n",
    "1. Find some reviews where your model fails to predict the sentiment correctly and give the reason why.\n",
    "2. Write 5 reviews on your own with at least 20 words. See if your model correctly predicts the sentiment on these reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yBu4_5FrFe-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment-2 NLP_f.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
